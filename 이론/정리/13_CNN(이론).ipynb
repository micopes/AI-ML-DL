{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13_CNN(간단한 이론).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c53meGHszXFc"
      },
      "source": [
        "## 이진 vs 다항"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_5FyTcOzXKn"
      },
      "source": [
        "- Keras의 경우 Crossentropy와 관련된 손실 함수가 너무 많고, 문서에서 너무 광범위한 내용을 설명하고 있기 때문에 간단하게 정리\r\n",
        "\r\n",
        "- Sigmoid vs Softmax\r\n",
        "  - Sigmoid는 Softmax의 특수 케이스로 클래스 개수만 2개일뿐 같은 연산\r\n",
        "  - Softmax는 하나의 Object가 여러 클래스를 가질 수 있는 다항 분류를 사용하고, 다항 분류의 경우 Softmax만 사용 가능\r\n",
        "  - 즉, 이진 -> 시그모이드, 다항 -> 소프트맥스\r\n",
        "  but, 시그모이드 -> 이진? 소프트맥스 -> 다항?\r\n",
        "  이는 맞지 않음\r\n",
        "\r\n",
        "- categorical_crossentropy vs sparse categorical crossentropy\r\n",
        "  - 멀티클래스 분류에 사용되는 것은 동일\r\n",
        "  - categorical은 레이블이 [0, 0, 1, 0, 0]과 같은 one-hot 형태여야 함\r\n",
        "  - sparse categorical은 레이블이 [1, 2, 3, 4]와 같은 정수 형태여야 함\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmMP4BoCzXMt"
      },
      "source": [
        "## 합성곱 신경망(CNN)\r\n",
        "- 뉴런들이 시야의 일부 범위 안에 있는 시각 자극에만 반응한다는 것을 알아냄 -> \r\n",
        "  1) 어떤 뉴런은 수평선의 이미지에만 반응하고,\r\n",
        "  2) 다른 뉴런은 다른 각도의 선분에만 반응\r\n",
        "  3) 어떤 뉴런은 큰 수용장을 가져서 저수준 패턴이 조합된 더 복잡한 패턴에 반응\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XjI4t4ezXOv"
      },
      "source": [
        "### 합성곱 층\r\n",
        "- CNN의 가장 중요한 구성요소는 합성곱 층(convolutional layer)\r\n",
        "- 이런 계층적 구조는 실제 이미지에서 흔히 볼 수 있으며, 이는 CNN이 이미지 인식에 잘 작동하는 이유 중 하나임"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu-QDLfz1Jdo"
      },
      "source": [
        "### 필터\r\n",
        "- 뉴런의 가중치는 수용장 크기의 작은 이미지로 표현될 수 있으며, 필터를 가중치를 부여할 수 있다.\r\n",
        "- 전체 뉴런에 적용된 하나의 필터는 하나의 특성 맵(feature map)을 만든다.\r\n",
        "- 특성 맵은 필터를 가장 크게 활성화시키는 이미지의 영역을 강조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCPUzFa91pWs"
      },
      "source": [
        "### 특성 맵(가중치) 쌓기\r\n",
        "- 각 특성 맵의 픽셀은 하나의 뉴런에 해당하고, 각각의 특성 맵마다 다른 파라미터를 사용하며, 하나의 특성맵에서의 모든 뉴런은 같은 파라미터를 공유한다.\r\n",
        "- 한 뉴런의 수용장은 앞서 설명한 것과 같으나, 이전 층의 모든 특성맵에 걸쳐 확장됨\r\n",
        "- 하나의 합성곱 층이 입력에 여러 필터를 동시에 적용하여 입력에 있는 여러 특징들을 감지할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEb9VWLR2C7V"
      },
      "source": [
        "### 풀링 층(Pooling Layer)\r\n",
        "- 풀링 층은 계산량과 **메모리 사용량, 과대적합을 줄이기 위한 파라미터를 줄이기 위해 입력 이미지의 축소본**을 만드는 것\r\n",
        "- CNN에서 몇 개의 층마다 최대 풀링 층을 추가하며, 전체적으로 일정 수준의 불변성을 얻을 수 있으며, 풀링 층을 사용하면 회전, 확대, 축소에 대한 약간의 불변성을 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voDGu5T32C5o"
      },
      "source": [
        "Conv -> Pool -> Conv -> Pool ... -> FC ...-> Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP4SrGHG2C3h"
      },
      "source": [
        "###특징 추출\r\n",
        "- Fashion MNIST와 같은 '이미지'는 어떤 특성을 찾아야 하는지 알기 쉽지 않다.\r\n",
        "  - 과거 Vision 연구에서 다양한 특징을 찾기 위한 연구를 진행\r\n",
        "  - 예를 들어, **SIFT(Scale-Invariant Feature Transform) 알고리즘을 이미지의 회전과 크기에 대해 변하지 않는 특징을 추출**해서 두 개의 이미지에서 서로 대응되는 부분을 찾음\r\n",
        "- CNN은 특징 추출 기법 중 하나인 컨볼루션 연산을 사용\r\n",
        "  - 컨볼루션 연산이란 각 픽셀과 그 주변의 픽셀의 조합으로 대체하는 동작\r\n",
        "  - 이 때, 연산에 사용되는 작은 행렬을 **필터(filter)**혹은 커널(kernel)이라고 한다.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uHrz9Zr2C0c"
      },
      "source": [
        "### CNN은 '특징을 추출하는 필터'를 생성\r\n",
        "- CNN은 \r\n",
        "  - 특징을 추출하는 부분(Conv, Pool..)과\r\n",
        "  - 분류를 하는 부분(FC(Flatten->Dense)->Softmax)으로 나뉜다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2qUlmzg2Cx1"
      },
      "source": [
        "### 드롭 아웃 레이아웃\r\n",
        "- 드롭아웃 레이어는 무작위로 뉴런의 부분집합을 제거하는 것으로, 드롭아웃 레이어는 학습 과정에서는 확률적으로 일부 뉴런에 대한 연결을 끊고, 테스트할 때는 정상적으로 모든 값을 포함해서 계산\r\n",
        "- tf.keras.layers.Dropout(rate = 0.3)\r\n",
        "  - rate는 제외할 뉴런의 비율을 나타냄\r\n",
        "  - 간단한 형태지만 AlexNet, VGG, GoogleLeNet, DenseNet 등 거의 모든 주요 CNN에 사용됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3uGxKll2CvW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmVXhAfG2Cs5"
      },
      "source": [
        ""
      ]
    }
  ]
}